{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb44b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from codex_template import run_codex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e46239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "models = [\n",
    "    'gpt-5.1-codex',    \n",
    "    'gpt-5.1-codex-max',     \n",
    "    'GPT-4 Turbo', \n",
    "    'gpt-5.1-chat-latest',\n",
    "    'gpt-5',\n",
    "    'gpt-4o'\n",
    "]\n",
    "languages = ['Python', 'C++', 'Rust', 'HTML', 'JavaScript', 'CSS', 'Go', 'Java', 'TypeScript']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bef0e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import api_key\n",
    "\n",
    "\n",
    "def code_generator_tool(model, language, message):\n",
    "    \"\"\"Generates production-grade code using the unified run_codex function\"\"\"\n",
    "    print(f'Code Generator tool called with model: {model}, language: {language}')\n",
    "\n",
    "    full_prompt = f\"\"\"\n",
    "    [System: You are an expert software engineering assistant. Generate production-grade, secure {language} code.]\n",
    "    [User: {message}]\n",
    "    \n",
    "    Requirements:\n",
    "    - Complete, functional code.\n",
    "    - {language} style guides (PEP 8, etc.).\n",
    "    - Security best practices.\n",
    "    - Docstrings and usage examples.\n",
    "    \"\"\"\n",
    "    return run_codex(full_prompt, model=model, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "433c0148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_explainer_tool(model, language, message):\n",
    "    print(f'Code Explainer tool called with model: {model}, language: {language}')\n",
    "    \n",
    "    full_prompt = f\"\"\"\n",
    "    [System: You are an expert code explainer for beginners. Explain this {language} code simply.]\n",
    "    [User: {message}]\n",
    "    \n",
    "    Structure:\n",
    "    1. Simple Summary\n",
    "    2. Step-by-Step Breakdown (Analogies)\n",
    "    3. Technical Details\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use the unified caller!\n",
    "    return run_codex(full_prompt, model=model, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43c20b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"code_generator_tool\",\n",
    "            \"description\": \"Generates code based on requirements\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"model\": {\"type\": \"string\", \"description\": \"Model to use for generation\"},\n",
    "                    \"language\": {\"type\": \"string\", \"description\": \"Programming language\"},\n",
    "                    \"message\": {\"type\": \"string\", \"description\": \"Code requirements\"}\n",
    "                },\n",
    "                \"required\": [\"model\", \"language\", \"message\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"code_explainer_tool\",\n",
    "            \"description\": \"Explains code snippets\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"model\": {\"type\": \"string\", \"description\": \"Model to use for explanation\"},\n",
    "                    \"language\": {\"type\": \"string\", \"description\": \"Programming language\"},\n",
    "                    \"message\": {\"type\": \"string\", \"description\": \"Code to explain\"}\n",
    "                },\n",
    "                \"required\": [\"model\", \"language\", \"message\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36ec6ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_calls(tool_calls, selected_model, language):\n",
    "    available_tools = {\n",
    "        \"code_generator_tool\": code_generator_tool,\n",
    "        \"code_explainer_tool\": code_explainer_tool\n",
    "    }\n",
    "    \n",
    "    tool_responses = []\n",
    "    \n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        function_args['model'] = selected_model\n",
    "        function_args['language'] = language\n",
    "        \n",
    "        if function_name in available_tools:\n",
    "            function_to_call = available_tools[function_name]\n",
    "            print(f\"Executing {function_name} using {selected_model}...\")\n",
    "            \n",
    "            result = function_to_call(**function_args)\n",
    "            \n",
    "            tool_responses.append({\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": str(result)\n",
    "            })\n",
    "    return tool_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b9d6da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_chatbot(target_model, language, message):\n",
    "    \"\"\"\n",
    "    Main function. \n",
    "    1. Uses a standard 'Smart' model (gpt-5.1-chat-latest) to understand intent and route tools.\n",
    "    2. The TOOLS themselves then use the 'target_model' (which might be the specialized Codex).\n",
    "    \"\"\"\n",
    "\n",
    "    router_model = \"gpt-5.1-chat-latest\" \n",
    "    \n",
    "    print(f\" Router ({router_model}) processing request...\")\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"You are a coding assistant. Route the user's request to generate or explain {language} code.\"},\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=router_model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",\n",
    "            max_completion_tokens=500\n",
    "        )\n",
    "        \n",
    "        if response.choices[0].message.tool_calls:\n",
    "            tool_calls = response.choices[0].message.tool_calls\n",
    "      \n",
    "            tool_responses = handle_tool_calls(tool_calls, target_model, language)\n",
    "            return tool_responses[0][\"content\"]\n",
    "            \n",
    "        else:\n",
    "            return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\\n\\nMake sure your API key is valid.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72bd63d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://678c40e0f6c0d2c5f8.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://678c40e0f6c0d2c5f8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Router (gpt-5.1-chat-latest) processing request...\n",
      " Router (gpt-5.1-chat-latest) processing request...\n",
      "Executing code_explainer_tool using gpt-4o...\n",
      "Code Explainer tool called with model: gpt-4o, language: Python\n",
      "Generating code using gpt-4o...\n",
      " Router (gpt-5.1-chat-latest) processing request...\n",
      "Executing code_generator_tool using gpt-4o...\n",
      "Code Generator tool called with model: gpt-4o, language: HTML\n",
      "Generating code using gpt-4o...\n",
      " Router (gpt-5.1-chat-latest) processing request...\n",
      "Executing code_generator_tool using gpt-4o...\n",
      "Code Generator tool called with model: gpt-4o, language: HTML\n",
      "Generating code using gpt-4o...\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# Codex-Powered Assistant\")\n",
    "    gr.Markdown(\"Uses `run_codex` to seamlessly switch between Standard and Agentic models.\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            model_dropdown = gr.Dropdown(\n",
    "                label=\" Select Target Model\",\n",
    "                choices=models,\n",
    "                value=models[5]\n",
    "            )\n",
    "            language_dropdown = gr.Dropdown(\n",
    "                label=\" Select Language\",\n",
    "                choices=languages,\n",
    "                value=\"Python\"\n",
    "            )\n",
    "            message_input = gr.Textbox(\n",
    "                label=\" Request\",\n",
    "                placeholder=\"Example: 'Create a snake game' or 'Explain this code...\",\n",
    "                lines=5\n",
    "            )\n",
    "            submit_btn = gr.Button(\"Submit\", variant=\"primary\")\n",
    "        \n",
    "        with gr.Column():\n",
    "            response_output = gr.Markdown(label=\" Response\")\n",
    "    \n",
    "    submit_btn.click(\n",
    "        fn=code_chatbot,\n",
    "        inputs=[model_dropdown, language_dropdown, message_input],\n",
    "        outputs=[response_output]\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7535d9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
