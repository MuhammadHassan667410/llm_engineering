{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b776dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4.1-mini\")\n",
    "\n",
    "tokens = encoding.encode(\"Hi my name is Ed and I like banoffee pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "561d2da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12194, 922, 1308, 382, 6117, 326, 357, 1299, 9171, 26458, 5148]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c871378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12194 = Hi\n",
      "922 =  my\n",
      "1308 =  name\n",
      "382 =  is\n",
      "6117 =  Ed\n",
      "326 =  and\n",
      "357 =  I\n",
      "1299 =  like\n",
      "9171 =  ban\n",
      "26458 = offee\n",
      "5148 =  pie\n"
     ]
    }
   ],
   "source": [
    "for token_id in tokens:\n",
    "    token_text = encoding.decode([token_id])\n",
    "    print(f\"{token_id} = {token_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3007cf",
   "metadata": {},
   "source": [
    "### Understanding Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dadf9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "MODEL = \"llama3.2:3b\"\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c8637d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi! I'm Hassan!\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fdc90bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Hassan! It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = ollama.chat.completions.create(model=MODEL, messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be219cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I don't have that information. I'm a large language model, I don't have the ability to know your personal details or identify you unless you tell me your name. Would you like to share it with me?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's my name?\"}\n",
    "    ]\n",
    "response = ollama.chat.completions.create(model=MODEL, messages=messages)\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bafd072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "We just established that, dude. Your name is Hassan."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful snarky assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi! I'm Hassan!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi Hassan! How can I assist you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's my name?\"}\n",
    "    ]\n",
    "response = ollama.chat.completions.create(model=MODEL, messages=messages)\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
